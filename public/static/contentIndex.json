{"On-System-Design":{"slug":"On-System-Design","filePath":"On System Design.md","title":"On System Design","links":[],"tags":["system-design","education"],"content":""},"The-tail-at-scale":{"slug":"The-tail-at-scale","filePath":"The tail at scale.md","title":"The tail at scale","links":[],"tags":["latency","distributed-systems","tail-tolerant","performance"],"content":"Takeaways\n\nHow to use replication to mock latency variability because of queueing delays\n\nHedged Request &amp; Tied Request\n\n\n\n\nWithin Request Short-Term Adaptations\nLatency variability Cause: queueing delays on the server before a request begins execution\nTwo techniques:\n\nHedged request\nTied request\n\n\nAn alternative to the tied-request and hedged-request schemes is to probe remote queues first, then submit the request to the least-loaded server. Problems:\n\nload levels can change between probe and request time\nclients can create temporary hot spots by all clients picking the same (least-loaded) server at the same time\n\n\nQ &amp; A\nQ. What is tail-tolerant?\nTail-tolerant is like fault-tolerant.\nFault-tolerant/Reliable systems are built from unreliable parts.\nTail-tolerant/Predictably responsive systems are built from less-predictable parts.\nQ. What do we mean when we talk about “latency” in a system?\nThe response time of the system for a client request.\nQ. Why Latency Variability Exists?\n\nprocesses/systems compete the shared resources\nbackground cron job is invoked\nQueuing delays:\n\nshort queue vs long queue\n\n\nMaintenance activities:\n\ndisk corruption triggers the distributed file system to re-construct the data on a new disk\nGarbage collection in the garbage collected programming languages\n\n\nHardware:\n\nEnergy management: inactive mode → active mode\n\n\n\nQ. Why does latency, and in particular the tail of the latency distribution in a system, matter? Who is impacted by it?\nA user request is divided into sub-requests, and the sub-requests fan out across hundreds or thousands of servers to parallelise the request processing.\nA single slow outlier can yield dramatic reductions in overall service performance.\n\nQ. In Reducing Component Variability section, the authors mention “Keep low-level queues short so higher-level policies take effect more quickly”. Why keep low-level queues short so higher-level policies take effect more quickly?\nThe low-level queues, such as the OS disk queue, are out of the application’s control.\nThey are not aware of the higher-level policies/prorities and they might serve the requests in a simple FIFO manner.\nIf these low-level queues are long, the application has to wait for many old requests to finish first.\nThe shallow low-level queues minimise the “distance” between the smart policy decisions and actual device execution.\nQ. How can a distributed system decrease this tail latency? Give one example.\nManaging background activities and synchronized disruption.\n\nSynchronise the background activities of all machines, so they execute at the same time, so that only user requests being handled in the synchronisation period are slow.\nThrottle the user requests during the synchronisation period to reduce the load of the system.\n"},"Unix-Time-Sharing-System":{"slug":"Unix-Time-Sharing-System","filePath":"Unix Time Sharing System.md","title":"Unix Time Sharing System","links":[],"tags":["operating-systems"],"content":"Takeaways\n\nAdministrative delegation is one of the differences between Unix layering and DNS layering\nThe implementation of the mount system call\n\nQ&amp;A\nQ. What things in UNIX are named?\n\nfile\nuser\n\nQ. Why set-user-ID?\nIt provides for privileged programs which may use files inaccessible to other users. For example, a program may keep an accounting file which should neither be read nor changed except by the program itself.\nQ. How does naming in UNIX compare to naming in DNS? How do layering and hierarchy apply (if at all)?\n\nUNIX filesystem\n\nLayering mainly provides naming context and access control\nNo strong notion of administrative delegation between directories\n\n\nDNS\n\nLayering primarily enables administrative delegation and distributed authority\nEach zone (subtree) can be delegated to different organizations\n\n\n\nQ. n = read(filep, buffer, count); when n == 0?\nThe file descriptor’s read pointer reached the end of the file.\nQ. What is the purpose of the open() syscall?\nThe open() syscall is used to use the pathname to search the corresponding i-number. Then it will store the i-number, device, read/write pointer into the system table indexed by the file descriptor.\nThe i-number is used to find the corresponding i-node.\nQ. Device number vs subdevice number\nThe device type indicates which system routine(code) will deal with I/O on that device.\n\nfor look up the driver table\n\nOne driver can handle many similar devices. The subdevice number tells the driver which one you’re talking to.\n\ne.g. tty driver for all pesudo-terminals\n\nQ. Explain the implementation of the mount syscall\nThe pathname of the mount point refers to the i-number of the special file that the file is specified in the mount syscall.\nThe path resolution of the mount point can find the root directory of the correct file system in the kernel’s Mount table.\nRef: landley.net/toybox/doc/mount.html"},"Virtual-Memory":{"slug":"Virtual-Memory","filePath":"Virtual Memory.md","title":"Virtual Memory","links":[],"tags":["operating-systems","memory"],"content":"\nQ. Why MMU(Memory Management Unit)?\nNormal memory access is not a kernel call. Without MMU, we cannot enforce memory protection. Other processes can overwrite other address spaces.\nQ. How can the MMU tell the CPU that something went wrong like page fault?\nMMU and CPU are tightly integrated hardware components. MMU uses direct hardware signalling (buses, flags) to notify the CPU. Then the CPU can abort the current instruction and trap into kernel mode. Then the kernel will handle the exception based on the trap handler.\nQ. How do multiple CPUs/Cores use the one MMU\nThey don’t literally share one single MMU. Each CPU core has its own independent MMU. If they do share a single MMU, the MMU will be a massive performance bottleneck.\nReferences\n\nweb.mit.edu/6.1800/www/lectures/s03-all.pdf\n"},"What-good-are-models-and-what-models-are-good":{"slug":"What-good-are-models-and-what-models-are-good","filePath":"What good are models and what models are good.md","title":"What good are models and what models are good","links":[],"tags":["distributed-systems","modeling"],"content":"Takeaways\n\nTo postulate a system is synchronous or asynchronous, we need to consider both processing speed and message delivery channel.\n\n\nPre-reading\nWhat good are models?\n\nsimplify the problem by making assumptions about what will/will not happen\n\n⇒ determine whether an implemented program is correct or not\n\nwhether the system behaviours are consistent with the model\n\n\nexp1. Failure mode: the node will not restart after it crashes\n\nSome persistence problems may not need to be worried about\n\n\nexp2. Message channel: no message will be altered\n\n\nunderstand the limitations of the solution\n\nexp.1. Consensus in the Byzantine failure model: 3f + 1 nodes at most tolerant f number of failures\nexp.2. Liveness in the asynchronous network is not possible if there is 1 node fails\n\n\n\nWhat models are good?\n\nRealistic ⇒ we can use the guaranteed properties in that model to solve real problems\n\nexp.1. Safety in the asynchronous network\n\n\n\n\nModel\nWhat is a model?\nA model for an object is a collection of attributes and a set of rules that govern how these attributes interact\nWhat good are models?\n\nThey can develop our intuition to understand the distributed systems.\nWe can answer different questions about the system by employing different models.\n\nFeasibility. What classes of problems can be solved?\nCost. For those classes that can be solved, how expensive must the solution be?\n\n\n\nWhat models are good?\nA good model is accurate and tractable.\n\naccurate: analyse it yields truths about the object of interest\ntractable: it is possible to analyse it\n\nThe Coordination Problem\nWe established that the Coordination Problem could not be solved by building a simple, informal model. Two insights were used in this model:\n\nAll protocols between two processes are equivalent to a series of message exchanges.\nActions taken by a process depend only on the sequence of messages it has received.\n\nSynchronous versus Asynchronous Systems\nPostulating that a system is asynchronous is a non-assumption. Every system is asynchronous. Even a system in which processes run in lock step (= no bound on processing speed) and message delivery is instantaneous satisfies the definition of an asynchronous system"},"index":{"slug":"index","filePath":"index.md","title":"R/W Systems","links":[],"tags":["distributed-systems","operating-systems"],"content":"Reading and writing about systems."}}